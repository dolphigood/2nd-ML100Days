{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Day097_Keras_CNN_vs_DNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TcUDMVEfSiBl","colab_type":"code","outputId":"a07cc0b0-91c6-41b0-ced3-31e4d91bed6b","executionInfo":{"status":"ok","timestamp":1564815930611,"user_tz":-480,"elapsed":2188,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import RMSprop, Adam\n","import os"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"a-bl7SBdSiB6","colab_type":"code","outputId":"0a8238ed-a870-47bf-85e7-bea85472858f","executionInfo":{"status":"ok","timestamp":1564815939827,"user_tz":-480,"elapsed":10064,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 10 # 訓練的 epochs 數量\n","\n","# 讀取資料並檢視\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"27jLgDjGSiCM","colab_type":"text"},"source":["## 首先我們使用一般的 DNN (MLP) 來訓練\n","由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"]},{"cell_type":"code","metadata":{"id":"5N4lRYtWSiCV","colab_type":"code","outputId":"e254d00d-04d1-40fe-f66c-dc9ad699d4f0","executionInfo":{"status":"ok","timestamp":1564815941342,"user_tz":-480,"elapsed":2021,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# 將資料攤平成一維資料\n","x_train = x_train.reshape(50000, 3072) \n","x_test = x_test.reshape(10000, 3072)\n","\n","# 將資料變為 float32 並標準化\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zDWOHkvkSiCk","colab_type":"code","outputId":"0bcff73d-6e5f-438c-e1df-b88b69dd981a","executionInfo":{"status":"ok","timestamp":1564815967328,"user_tz":-480,"elapsed":26003,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(3072,)))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0803 07:05:36.076182 140704047298432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0803 07:05:36.117893 140704047298432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0803 07:05:36.123893 140704047298432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0803 07:05:36.140902 140704047298432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0803 07:05:36.149863 140704047298432 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0803 07:05:36.219163 140704047298432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0803 07:05:36.231711 140704047298432 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0803 07:05:36.344173 140704047298432 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 512)               1573376   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 1,841,162\n","Trainable params: 1,841,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","50000/50000 [==============================] - 6s 117us/step - loss: 2.1301 - acc: 0.2472 - val_loss: 1.8521 - val_acc: 0.3063\n","Epoch 2/10\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.8589 - acc: 0.3266 - val_loss: 1.7887 - val_acc: 0.3418\n","Epoch 3/10\n","50000/50000 [==============================] - 2s 42us/step - loss: 1.7881 - acc: 0.3561 - val_loss: 1.7403 - val_acc: 0.3907\n","Epoch 4/10\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.7415 - acc: 0.3735 - val_loss: 1.6652 - val_acc: 0.4086\n","Epoch 5/10\n","50000/50000 [==============================] - 2s 42us/step - loss: 1.7047 - acc: 0.3884 - val_loss: 1.6353 - val_acc: 0.4109\n","Epoch 6/10\n","50000/50000 [==============================] - 2s 42us/step - loss: 1.6806 - acc: 0.3999 - val_loss: 1.6408 - val_acc: 0.4188\n","Epoch 7/10\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.6597 - acc: 0.4051 - val_loss: 1.6023 - val_acc: 0.4331\n","Epoch 8/10\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.6425 - acc: 0.4131 - val_loss: 1.5860 - val_acc: 0.4441\n","Epoch 9/10\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.6273 - acc: 0.4188 - val_loss: 1.5535 - val_acc: 0.4504\n","Epoch 10/10\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.6177 - acc: 0.4217 - val_loss: 1.5608 - val_acc: 0.4546\n","Test loss: 1.5607838314056397\n","Test accuracy: 0.4546\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EM5K7luHSiC0","colab_type":"text"},"source":["## 接下來我們使用 CNN 來訓練神經網路\n","CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"]},{"cell_type":"code","metadata":{"id":"VZsgR0SsSiC4","colab_type":"code","outputId":"5838ece0-3572-478f-de10-9188f9e8df6a","executionInfo":{"status":"ok","timestamp":1564817014387,"user_tz":-480,"elapsed":66631,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v-FiTd65SiDG","colab_type":"code","outputId":"3e200e9e-45d7-4193-a436-c17b7c1ec92a","executionInfo":{"status":"ok","timestamp":1564817014077,"user_tz":-480,"elapsed":66375,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_27 (Conv2D)           (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_40 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_41 (Activation)   (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_42 (Activation)   (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_43 (Activation)   (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_24 (Dropout)         (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 512)               1180160   \n","_________________________________________________________________\n","activation_44 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 10)                5130      \n","_________________________________________________________________\n","activation_45 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","50000/50000 [==============================] - 7s 147us/step - loss: 1.7532 - acc: 0.3660 - val_loss: 1.3378 - val_acc: 0.5130\n","Epoch 2/10\n","50000/50000 [==============================] - 6s 126us/step - loss: 1.3185 - acc: 0.5316 - val_loss: 1.1312 - val_acc: 0.6063\n","Epoch 3/10\n","50000/50000 [==============================] - 6s 126us/step - loss: 1.1085 - acc: 0.6096 - val_loss: 1.0705 - val_acc: 0.6335\n","Epoch 4/10\n","50000/50000 [==============================] - 6s 126us/step - loss: 0.9708 - acc: 0.6615 - val_loss: 1.0415 - val_acc: 0.6495\n","Epoch 5/10\n","50000/50000 [==============================] - 6s 125us/step - loss: 0.8716 - acc: 0.6959 - val_loss: 0.8396 - val_acc: 0.7109\n","Epoch 6/10\n","50000/50000 [==============================] - 6s 125us/step - loss: 0.8059 - acc: 0.7178 - val_loss: 0.7955 - val_acc: 0.7278\n","Epoch 7/10\n","50000/50000 [==============================] - 6s 126us/step - loss: 0.7538 - acc: 0.7402 - val_loss: 0.7344 - val_acc: 0.7501\n","Epoch 8/10\n","50000/50000 [==============================] - 6s 127us/step - loss: 0.7136 - acc: 0.7534 - val_loss: 0.7607 - val_acc: 0.7424\n","Epoch 9/10\n","50000/50000 [==============================] - 6s 127us/step - loss: 0.6830 - acc: 0.7643 - val_loss: 0.7378 - val_acc: 0.7507\n","Epoch 10/10\n","50000/50000 [==============================] - 6s 127us/step - loss: 0.6506 - acc: 0.7745 - val_loss: 0.6918 - val_acc: 0.7689\n","Test loss: 0.6917996832847595\n","Test accuracy: 0.7689\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iZxXlUc3SiDY","colab_type":"text"},"source":["## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"]},{"cell_type":"markdown","metadata":{"id":"7rqdJmrGSiDq","colab_type":"text"},"source":["## 作業\n","1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n","    - 試著移除拿除一次捲積層，Test Accuracy會下降\n","    - \n","    \n","2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?\n","    - DNN的參數較多，原因為CNN有Pooling Layer，可以降維減少需要的參數量。"]},{"cell_type":"code","metadata":{"id":"kBUo525lSiDv","colab_type":"code","outputId":"c9424c2d-bae1-4b36-9a7d-9530c76ddda6","executionInfo":{"status":"ok","timestamp":1564816121075,"user_tz":-480,"elapsed":1384,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ad_vA9o_Tr2L","colab_type":"code","outputId":"195a04c1-6b6e-43a9-c6cd-6c2f33255cda","executionInfo":{"status":"ok","timestamp":1564817250226,"user_tz":-480,"elapsed":57588,"user":{"displayName":"Po-Chou Chu","photoUrl":"https://lh4.googleusercontent.com/-zJjPHOquPHs/AAAAAAAAAAI/AAAAAAAAG_I/ykFSjs_CUbM/s64/photo.jpg","userId":"01386996996793040190"}},"colab":{"base_uri":"https://localhost:8080/","height":999}},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","#model.add(Conv2D(64, (5, 5), padding='same'))\n","#model.add(Activation('relu'))\n","#model.add(Conv2D(64, (5, 5)))\n","#model.add(Activation('relu'))\n","#model.add(MaxPooling2D(pool_size=(2, 2)))\n","#model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_33 (Conv2D)           (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_50 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_34 (Conv2D)           (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_51 (Activation)   (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_28 (Dropout)         (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 7200)              0         \n","_________________________________________________________________\n","dense_22 (Dense)             (None, 512)               3686912   \n","_________________________________________________________________\n","activation_52 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_23 (Dense)             (None, 10)                5130      \n","_________________________________________________________________\n","activation_53 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 3,702,186\n","Trainable params: 3,702,186\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","50000/50000 [==============================] - 7s 134us/step - loss: 1.5821 - acc: 0.4403 - val_loss: 1.2508 - val_acc: 0.5693\n","Epoch 2/10\n","50000/50000 [==============================] - 5s 109us/step - loss: 1.1716 - acc: 0.5899 - val_loss: 1.0679 - val_acc: 0.6198\n","Epoch 3/10\n","50000/50000 [==============================] - 5s 108us/step - loss: 1.0097 - acc: 0.6472 - val_loss: 0.9605 - val_acc: 0.6649\n","Epoch 4/10\n","50000/50000 [==============================] - 5s 108us/step - loss: 0.9103 - acc: 0.6845 - val_loss: 0.9162 - val_acc: 0.6868\n","Epoch 5/10\n","50000/50000 [==============================] - 5s 106us/step - loss: 0.8242 - acc: 0.7134 - val_loss: 0.9627 - val_acc: 0.6660\n","Epoch 6/10\n","50000/50000 [==============================] - 5s 107us/step - loss: 0.7525 - acc: 0.7394 - val_loss: 1.0994 - val_acc: 0.6275\n","Epoch 7/10\n","50000/50000 [==============================] - 5s 107us/step - loss: 0.6985 - acc: 0.7598 - val_loss: 0.8446 - val_acc: 0.7169\n","Epoch 8/10\n","50000/50000 [==============================] - 5s 108us/step - loss: 0.6450 - acc: 0.7771 - val_loss: 0.9369 - val_acc: 0.6951\n","Epoch 9/10\n","50000/50000 [==============================] - 5s 106us/step - loss: 0.6147 - acc: 0.7885 - val_loss: 0.8469 - val_acc: 0.7112\n","Epoch 10/10\n","50000/50000 [==============================] - 5s 108us/step - loss: 0.5779 - acc: 0.8035 - val_loss: 0.9343 - val_acc: 0.7198\n","Test loss: 0.9343344904899598\n","Test accuracy: 0.7198\n"],"name":"stdout"}]}]}